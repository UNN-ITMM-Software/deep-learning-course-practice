{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод обратного распространения ошибки для обучения глубоких нейронных сетей на примере двухслойной полностью связанной сети (один скрытый слой)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общая схема метода обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализация синаптических весов сети (случайным образом из некоторого распределения)  \n",
    "Повторение следующих шагов для каждого примера \n",
    "тренировочного набора данных\n",
    "1. Прямой проход:\n",
    "* Вычисление значений выходных сигналов нейронов всех слоев\n",
    "* Вычисление значений производных функций активации на каждом слое сети\n",
    "2. Обратный проход:\n",
    "* Вычисление значения целевой функции и ее градиента\n",
    "* Корректировка синаптических весов  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 60000\n",
      "Number of test samples: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 16 # на каждой итерации рассматриваем сразу 16 обучающих примеров\n",
    "num_epochs = 20 # повторяем 20 раз по всему набору тренировок\n",
    "\n",
    "w, h = 28, 28 # изображения MNIST имеют размер 28x28\n",
    "num_classes = 10 # существует 10 классов (по 1 на цифру)\n",
    "hidden_neurons = 300 # количество скрытых нейронов\n",
    "learning_rate = 0.1 # скорость обучения\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() # извлекаем данные MNIST\n",
    "\n",
    "# Выведем на экран хранящееся в X_train[0] изображение\n",
    "fig = plt.figure(figsize = (1, 1))\n",
    "plt.imshow(X_train[0], cmap = 'binary')\n",
    "plt.axis('off')\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], w * h)\n",
    "X_test = X_test.reshape(X_test.shape[0], w * h)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255 # нормализуем данные до диапазона [0, 1]\n",
    "X_test /= 255 # Нормализуем данные до диапазона [0, 1]\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes) # кодирование меток\n",
    "y_test = np_utils.to_categorical(y_test, num_classes) # кодирование меток\n",
    "\n",
    "print('Number of train samples: {}'.format(len(X_train)))\n",
    "print('Number of test samples: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция активации на скрытом слое\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# функция активации на выходном слое\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x, axis = 1, keepdims = True)\n",
    "\n",
    "# функция ошибки\n",
    "def crossEntropyLoss(y, u):\n",
    "    return np.mean(-np.sum(y * np.log(u), axis = 1))\n",
    "\n",
    "def get_accuracy(x, y):\n",
    "    return np.mean(np.argmax(x, axis = 1) == np.argmax(y, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNNetwork:\n",
    "    # конструктор класса\n",
    "    def __init__(self,\n",
    "            num_of_neurons_input, # количество нейронов на входе\n",
    "            num_of_neurons_hidden_layer, # количество нейронов на скрытом слое\n",
    "            num_of_neurons_output, # количество нейронов на выходе\n",
    "            batch_size, # размер пачки\n",
    "            learning_rate # скорость обучения\n",
    "                ):\n",
    "        \n",
    "        self.W1 = np.random.randn(num_of_neurons_input, num_of_neurons_hidden_layer) * 0.01\n",
    "        self.W2 = np.random.randn(num_of_neurons_hidden_layer, num_of_neurons_output) * 0.01\n",
    "        self.b1 = np.zeros((1, num_of_neurons_hidden_layer))\n",
    "        self.b2 = np.zeros((1, num_of_neurons_output))\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "                      \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.v1 = np.dot(x, self.W1) + self.b1\n",
    "        self.val_ReLU = ReLU(self.v1)\n",
    "        self.v2 = np.dot(self.val_ReLU, self.W2) + self.b2\n",
    "        self.val_softmax = softmax(self.v2)\n",
    "        return self.val_softmax\n",
    "    \n",
    "    \n",
    "    def backward(self, x, y):\n",
    "        dv2 = (self.val_softmax - y) / self.val_softmax.shape[0]\n",
    "        dW2 = (self.val_ReLU.T).dot(dv2)\n",
    "        db2 = np.sum(dv2, axis = 0, keepdims = True)\n",
    "        dReLU = np.where(self.v1 > 0, 1, 0)\n",
    "        dv1 = dv2.dot(self.W2.T) * dReLU\n",
    "        dW1 = np.dot(x.T, dv1)\n",
    "        db1 = np.sum(dv1, axis = 0, keepdims = True)\n",
    "\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "    \n",
    "    \n",
    "    def train(self, x, y, epochs):\n",
    "        start = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            start_epoch = time.time()\n",
    "            for i in range(0, len(x), self.batch_size):\n",
    "                x_curr = x[i : i + self.batch_size]\n",
    "                y_curr = y[i : i + self.batch_size]\n",
    "                self.forward(x_curr)\n",
    "                self.backward(x_curr, y_curr)\n",
    "        \n",
    "            self.forward(x)\n",
    "            print('epoch[{}]: err = {} accuracy_train = {}    time = {}'.format(epoch, \n",
    "                                                                             crossEntropyLoss(y, self.val_softmax), \n",
    "                                                                             get_accuracy(y, self.val_softmax), \n",
    "                                                                             time.time() - start_epoch))\n",
    "        print('total time = ', time.time() - start)\n",
    "    \n",
    "    \n",
    "    def test(self, x, y):\n",
    "        self.forward(x)\n",
    "        print('accuracy_test =', get_accuracy(y, self.val_softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание объекта разработанного класса\n",
    "nnetwork = myNNetwork(w * h, hidden_neurons, num_classes, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0]: err = 0.1487892813475456 accuracy_train = 0.9538166666666666    time = 6.108664512634277\n",
      "epoch[1]: err = 0.09179168022704859 accuracy_train = 0.97175    time = 6.127614736557007\n",
      "epoch[2]: err = 0.0683285151268718 accuracy_train = 0.9785166666666667    time = 6.378942251205444\n",
      "epoch[3]: err = 0.05157898955995491 accuracy_train = 0.9838333333333333    time = 6.599353551864624\n",
      "epoch[4]: err = 0.040474343836677765 accuracy_train = 0.9871666666666666    time = 7.1448938846588135\n",
      "epoch[5]: err = 0.032179516597996345 accuracy_train = 0.9900333333333333    time = 6.958392143249512\n",
      "epoch[6]: err = 0.02677470456253492 accuracy_train = 0.9919166666666667    time = 6.891571283340454\n",
      "epoch[7]: err = 0.023758838149236104 accuracy_train = 0.9924333333333333    time = 7.831059694290161\n",
      "epoch[8]: err = 0.020713095111639438 accuracy_train = 0.9935333333333334    time = 7.376308441162109\n",
      "epoch[9]: err = 0.01833190791762738 accuracy_train = 0.9946    time = 7.036150932312012\n",
      "epoch[10]: err = 0.01612064473596259 accuracy_train = 0.9952833333333333    time = 6.99329948425293\n",
      "epoch[11]: err = 0.01364536398781491 accuracy_train = 0.9962166666666666    time = 7.446087598800659\n",
      "epoch[12]: err = 0.011801275411677643 accuracy_train = 0.9967333333333334    time = 7.256596326828003\n",
      "epoch[13]: err = 0.008154309345216703 accuracy_train = 0.9981666666666666    time = 6.746957778930664\n",
      "epoch[14]: err = 0.00630005943162189 accuracy_train = 0.9988666666666667    time = 7.291503190994263\n",
      "epoch[15]: err = 0.005229816905215957 accuracy_train = 0.9991166666666667    time = 6.728008270263672\n",
      "epoch[16]: err = 0.004535361564048799 accuracy_train = 0.9993833333333333    time = 6.878606796264648\n",
      "epoch[17]: err = 0.0038881117786182333 accuracy_train = 0.99955    time = 6.775881290435791\n",
      "epoch[18]: err = 0.0033811222956425515 accuracy_train = 0.99965    time = 6.8626487255096436\n",
      "epoch[19]: err = 0.0029618060566782237 accuracy_train = 0.9998    time = 6.804803848266602\n",
      "total time =  138.24433040618896\n"
     ]
    }
   ],
   "source": [
    "nnetwork.train(X_train, y_train, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_test = 0.983\n"
     ]
    }
   ],
   "source": [
    "nnetwork.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение полученной точности с точностью, которую выдают стандартные инструменты глубокого обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим библиотеку PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNetwork(\n",
      "  (linear1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=300, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNetwork, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(w * h, hidden_neurons)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(hidden_neurons, num_classes)\n",
    "        \n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return torch.nn.functional.log_softmax(x, dim = 1)\n",
    "\n",
    "\n",
    "nnetwork = NNetwork()\n",
    "print(nnetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0]: err = 0.01622287929058075 accuracy_train = 0.9599    time = 2.9142072200775146\n",
      "epoch[1]: err = 0.0053890785202383995 accuracy_train = 0.9743166666666667    time = 2.8423991203308105\n",
      "epoch[2]: err = 0.0028351792134344578 accuracy_train = 0.9810166666666666    time = 2.9750442504882812\n",
      "epoch[3]: err = 0.0017842091619968414 accuracy_train = 0.9845833333333334    time = 3.1147046089172363\n",
      "epoch[4]: err = 0.0015489938668906689 accuracy_train = 0.98735    time = 2.9929637908935547\n",
      "epoch[5]: err = 0.0017016457859426737 accuracy_train = 0.9892833333333333    time = 3.0408687591552734\n",
      "epoch[6]: err = 0.001408482319675386 accuracy_train = 0.9914333333333334    time = 3.3929219245910645\n",
      "epoch[7]: err = 0.00114916090387851 accuracy_train = 0.993    time = 3.7798922061920166\n",
      "epoch[8]: err = 0.0013710242928937078 accuracy_train = 0.9935    time = 3.246319055557251\n",
      "epoch[9]: err = 0.0010984452674165368 accuracy_train = 0.9947166666666667    time = 3.2812256813049316\n",
      "epoch[10]: err = 0.0011371112195774913 accuracy_train = 0.9953166666666666    time = 3.1296327114105225\n",
      "epoch[11]: err = 0.0007758524734526873 accuracy_train = 0.99655    time = 3.1126749515533447\n",
      "epoch[12]: err = 0.00036021327832713723 accuracy_train = 0.9982    time = 3.161576986312866\n",
      "epoch[13]: err = 0.00029686855850741267 accuracy_train = 0.9986    time = 3.1984152793884277\n",
      "epoch[14]: err = 0.0002022434346145019 accuracy_train = 0.9989833333333333    time = 3.1854820251464844\n",
      "epoch[15]: err = 0.0001788448280422017 accuracy_train = 0.99925    time = 3.132657289505005\n",
      "epoch[16]: err = 0.00014897240907885134 accuracy_train = 0.9994666666666666    time = 3.1615118980407715\n",
      "epoch[17]: err = 0.0001365526404697448 accuracy_train = 0.9995833333333334    time = 3.1655354499816895\n",
      "epoch[18]: err = 0.00011639526928775012 accuracy_train = 0.9997333333333334    time = 3.1346185207366943\n",
      "epoch[19]: err = 0.00010742247104644775 accuracy_train = 0.9998333333333334    time = 3.1884734630584717\n",
      "total time =  63.15811371803284\n"
     ]
    }
   ],
   "source": [
    "# Обучение построенной модели на CPU\n",
    "\n",
    "# Выбор устройства для вычислений\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "nnetwork.to(device)\n",
    "\n",
    "# Функция ошибки на этапе обучения\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Метод оптимизации для обучения параметров\n",
    "optimizer = torch.optim.SGD(nnetwork.parameters(), lr = learning_rate)\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    start_epoch = time.time()\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        x_curr = torch.tensor(X_train[i : i + batch_size])\n",
    "        y_curr = torch.tensor(y_train[i : i + batch_size]) \n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = nnetwork(x_curr) # вычисление выхода сети\n",
    "        loss = loss_function(outputs, y_curr) # вычисление функции ошибки\n",
    "        \n",
    "        # Обратный проход\n",
    "        optimizer.zero_grad() # обнуление всех вычисляемых градиентов\n",
    "        loss.backward() # вычисление градиента функции ошибки\n",
    "        optimizer.step() # обновление параметров модели\n",
    "        \n",
    "    print('epoch[{}]: err = {} accuracy_train = {}    time = {}'.format(epoch, \n",
    "                                                                        loss.item(), \n",
    "                                                                        get_accuracy(nnetwork(\n",
    "                                                                            torch.tensor(X_train)).detach().numpy(), \n",
    "                                                                                     y_train), \n",
    "                                                                        time.time() - start_epoch))\n",
    "        \n",
    "\n",
    "print('total time = ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_test = 0.9826\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_test =', get_accuracy(nnetwork(torch.tensor(X_test)).detach().numpy(), y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

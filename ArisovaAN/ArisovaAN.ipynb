{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d19198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a7e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(folder_path: str):\n",
    "    \"\"\" Загрузка данных MNIST - рукописные цифры\n",
    "        param: folder_path - путь до папки с файлами из http://yann.lecun.com/exdb/mnist/\n",
    "    \"\"\"\n",
    "    x_train = idx2numpy.convert_from_file(folder_path + 'train-images.idx3-ubyte')\n",
    "    x_test = idx2numpy.convert_from_file(folder_path + 't10k-images.idx3-ubyte')\n",
    "    \n",
    "    y_train = idx2numpy.convert_from_file(folder_path + 'train-labels.idx1-ubyte')\n",
    "    y_test = idx2numpy.convert_from_file(folder_path + 't10k-labels.idx1-ubyte')\n",
    "    \n",
    "    train_size, test_size = x_train.shape[0], x_test.shape[0]\n",
    "    \n",
    "    return x_train.reshape(train_size, 28 * 28) / 255, x_test.reshape(test_size, 28 * 28) / 255, \\\n",
    "           y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0e2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = get_train_test_data('mnist-data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc0a46",
   "metadata": {},
   "source": [
    "# Custom NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "464822e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork:\n",
    "    def __init__(self, layers: list[int]):\n",
    "        \"\"\" Структура сети:\n",
    "            input -> hidden_layer_1 -> relu_layer -> hidden_layer_2 -> softmax\n",
    "            Лосс-функция: CrossEntropyLoss\n",
    "            params: \n",
    "                layers - список с количеством нейронов в каждом слое, len(layers) = 3\n",
    "        \"\"\"\n",
    "        self.weights = [np.random.randn(layers[0], layers[1]) * 0.01 + 0.01, \n",
    "                        np.random.randn(layers[1], layers[2]) * 0.01 + 0.01]\n",
    "        \n",
    "        self.bias = [np.random.randn(1, layers[1]), \n",
    "                     np.random.randn(1, layers[2])]\n",
    "        \n",
    "        self._print_pattern = 'Epoch {} \\t Time {:.2f}s \\t Loss {:.4f} \\t Accuracy {:.4f}'\n",
    "        self._report_pattern = '{0} time {1:.2f}s \\t {0} loss {2:.4f} \\t {0} accuracy {3:.4f}'\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" Прямой проход по нейронной сети.\n",
    "        Цель: запомнить состояние всех слоев и вычислить результат.\n",
    "        Запоманием hidden_layer_1, relu_layer, hidden_layer_2 перед softmax.\n",
    "        Всё это нужно для backprob.\n",
    "        params:\n",
    "            x - input, shape: (batch_size, dim)\n",
    "        \"\"\"\n",
    "        self.hidden_layer_1 = x @ self.weights[0] + self.bias[0]\n",
    "        self.relu_layer = self.relu(self.hidden_layer_1)\n",
    "        self.hidden_layer_2 = self.relu_layer @ self.weights[1] + self.bias[1]\n",
    "        return self.softmax(self.hidden_layer_2)\n",
    "    \n",
    "    def backward(self, x, y_true, y_pred):\n",
    "        \"\"\" Обратный проход по нейронной сети. \n",
    "        Цель: вычислить производные cross entropy loss по каждому параметру нейронной сети\n",
    "        self.derivate_weights - производные по весам\n",
    "        self.derivate_bias - производные по байесам\n",
    "        Нужно для очередного шага градиентного спуска.\n",
    "        params:\n",
    "            x - input, shape: (batch_size, dim)\n",
    "            y_true - true targets, shape: (batch_size, num_classes) - one hot encoding\n",
    "            y_pred - predict targets, shape: (batch_size, num_classes) - one hot encoding\n",
    "        \"\"\"\n",
    "        derivate_hidden_layer_2 = (y_pred - y_true) / y_true.shape[0]\n",
    "        \n",
    "        weight2 = self.relu_layer.T @ derivate_hidden_layer_2\n",
    "        bias2 = np.sum(derivate_hidden_layer_2, axis=0)\n",
    "        \n",
    "        derivate_hidden_layer_1 = (derivate_hidden_layer_2 @ self.weights[1].T) * self.derivate_relu(self.hidden_layer_1)\n",
    "        \n",
    "        weight1 = x.T @ derivate_hidden_layer_1\n",
    "        bias1 = np.sum(derivate_hidden_layer_1, axis=0)\n",
    "        \n",
    "        self.derivate_weights = [weight1, weight2]\n",
    "        self.derivate_bias = [bias1, bias2]\n",
    "    \n",
    "    def optimizer_step(self, lr):\n",
    "        \"\"\" Шаг стохастического градиентного спуска.\n",
    "        Для этого используем найденные производные self.self.derivate_weights и self.derivate_bias.\n",
    "            params:\n",
    "                lr - скорость обучения (learning_rate)\n",
    "        \"\"\"\n",
    "        self.weights = [w - lr * d for w, d in zip(self.weights, self.derivate_weights)]\n",
    "        self.bias = [b - lr * d for b, d in zip(self.bias, self.derivate_bias)]\n",
    "\n",
    "    def fit(self, x_train, y_train, *, epochs, lr, batch_size):\n",
    "        \"\"\" Обучение нейронной сети. \n",
    "        Эпоха - выполнение последовательности forward -> backward -> optimizer_step для всей обучающей\n",
    "        выборки.\n",
    "            params:\n",
    "                x_train - обучающая выборка\n",
    "                y_train - таргеты (будет сделан one_hot_encoding, если нужно)\n",
    "                keyword_args:\n",
    "                    epochs - количество эпох\n",
    "                    lr - learning_rate\n",
    "                    batch_size - размер пачки\n",
    "        \"\"\"\n",
    "        \n",
    "        if y_train.size == y_train.shape[0]:\n",
    "            y_train = self.one_hot_encoding(y_train)\n",
    "        \n",
    "        start_train = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            start_epoch = time.time()\n",
    "            it, train_loss, accuracy_train = 0, [], []\n",
    "            while it < len(x_train):\n",
    "                x_batch = x_train[it:it + batch_size]\n",
    "                y_batch = y_train[it:it + batch_size]\n",
    "\n",
    "                y_pred = self.forward(x_batch)\n",
    "                self.backward(x_batch, y_batch, y_pred)\n",
    "                self.optimizer_step(lr)\n",
    "                \n",
    "                train_loss.append(self.cross_entropy_loss(y_pred, y_batch))\n",
    "                accuracy_train.append(self.accuracy_score(y_pred, y_batch))\n",
    "                \n",
    "                it += batch_size\n",
    "\n",
    "            epoch_time = time.time() - start_epoch\n",
    "            \n",
    "            loss = np.mean(train_loss)\n",
    "            accuracy = np.mean(accuracy_train)\n",
    "            \n",
    "            print(self._print_pattern.format(epoch + 1, epoch_time, loss, accuracy))\n",
    "\n",
    "        train_time = time.time() - start_train\n",
    "        print('\\n.............................FINISH.............................\\n')\n",
    "        print(self._report_pattern.format('Train', train_time, loss, accuracy))\n",
    "\n",
    "    def get_test_score(self, x_test, y_test, *, batch_size):\n",
    "        \"\"\" Проверка на тестовых данных.\n",
    "        Accuracy score для тестовых данных\n",
    "            params:\n",
    "                x_test - тестовая выборка\n",
    "                y_test - таргеты (будет сделан one_hot_encoding, если нужно)\n",
    "        \"\"\"\n",
    "        if y_test.size == y_test.shape[0]:\n",
    "            y_test = self.one_hot_encoding(y_test)\n",
    "        \n",
    "        test_time = time.time()\n",
    "        it, test_loss, accuracy_test = 0, [], []\n",
    "        while it < x_test.shape[0]:\n",
    "            x_batch = x_test[it:it + batch_size]\n",
    "            y_batch = y_test[it:it + batch_size]\n",
    "            \n",
    "            y_pred = self.forward(x_batch)\n",
    "            \n",
    "            test_loss.append(self.cross_entropy_loss(y_pred, y_batch))\n",
    "            accuracy_test.append(self.accuracy_score(y_pred, y_batch))\n",
    "            \n",
    "            it += batch_size\n",
    "        \n",
    "        loss = np.mean(test_loss)\n",
    "        accuracy = np.mean(accuracy_test)\n",
    "        \n",
    "        print(self._report_pattern.format('Test', time.time() - test_time, loss, accuracy))\n",
    "\n",
    "    @staticmethod\n",
    "    def derivate_relu(x):\n",
    "        return (x > 0).astype(np.int_)\n",
    "    \n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "    \n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(y_pred, y_true):\n",
    "        return np.mean(-np.sum(y_true * np.log(y_pred), axis=1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def one_hot_encoding(y):\n",
    "        n_labels = max(y) + 1\n",
    "        return np.eye(n_labels)[y]\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy_score(y_pred, y_true):\n",
    "        y_pred_classes = np.argmax(y_true, axis=1)\n",
    "        y_true_classes = np.argmax(y_pred, axis=1)\n",
    "        return np.mean(y_pred_classes == y_true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac163f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t Time 3.14s \t Loss 0.5599 \t Accuracy 0.8461\n",
      "Epoch 2 \t Time 3.00s \t Loss 0.2541 \t Accuracy 0.9266\n",
      "Epoch 3 \t Time 3.08s \t Loss 0.1924 \t Accuracy 0.9448\n",
      "Epoch 4 \t Time 3.17s \t Loss 0.1522 \t Accuracy 0.9565\n",
      "Epoch 5 \t Time 3.14s \t Loss 0.1250 \t Accuracy 0.9648\n",
      "Epoch 6 \t Time 3.19s \t Loss 0.1056 \t Accuracy 0.9702\n",
      "Epoch 7 \t Time 3.05s \t Loss 0.0911 \t Accuracy 0.9748\n",
      "Epoch 8 \t Time 3.17s \t Loss 0.0798 \t Accuracy 0.9778\n",
      "Epoch 9 \t Time 3.03s \t Loss 0.0707 \t Accuracy 0.9805\n",
      "Epoch 10 \t Time 3.13s \t Loss 0.0630 \t Accuracy 0.9825\n",
      "Epoch 11 \t Time 3.07s \t Loss 0.0566 \t Accuracy 0.9847\n",
      "Epoch 12 \t Time 3.07s \t Loss 0.0510 \t Accuracy 0.9867\n",
      "Epoch 13 \t Time 3.05s \t Loss 0.0461 \t Accuracy 0.9882\n",
      "Epoch 14 \t Time 3.11s \t Loss 0.0419 \t Accuracy 0.9895\n",
      "Epoch 15 \t Time 3.07s \t Loss 0.0382 \t Accuracy 0.9907\n",
      "Epoch 16 \t Time 3.08s \t Loss 0.0348 \t Accuracy 0.9918\n",
      "Epoch 17 \t Time 3.06s \t Loss 0.0319 \t Accuracy 0.9926\n",
      "Epoch 18 \t Time 3.04s \t Loss 0.0292 \t Accuracy 0.9935\n",
      "Epoch 19 \t Time 3.01s \t Loss 0.0268 \t Accuracy 0.9945\n",
      "Epoch 20 \t Time 3.07s \t Loss 0.0246 \t Accuracy 0.9950\n",
      "\n",
      ".............................FINISH.............................\n",
      "\n",
      "Train time 61.75s \t Train loss 0.0246 \t Train accuracy 0.9950\n",
      "Test time 0.09s \t Test loss 0.0683 \t Test accuracy 0.9788\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNeuralNetwork([784, 300, 10])\n",
    "model.fit(x_train, y_train, epochs=20, lr=0.1, batch_size=64)\n",
    "model.get_test_score(x_test, y_test,  batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25b30e",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8880cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.FloatTensor(self.x[i]), self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95534f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(Dataset(x_train, y_train), batch_size=64)\n",
    "test_loader = torch.utils.data.DataLoader(Dataset(x_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7613ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ecf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(data_loader, model):\n",
    "    tp = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n += y.size(0)\n",
    "            tp += int((predicted == y).sum())\n",
    "    return tp / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "004d737b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, train_accuracy 0.855\n",
      "Epoch 1, test_accuracy 0.8636\n",
      "\n",
      "\n",
      "Epoch 2, train_accuracy 0.8861333333333333\n",
      "Epoch 2, test_accuracy 0.8926\n",
      "\n",
      "\n",
      "Epoch 3, train_accuracy 0.89755\n",
      "Epoch 3, test_accuracy 0.9027\n",
      "\n",
      "\n",
      "Epoch 4, train_accuracy 0.9053333333333333\n",
      "Epoch 4, test_accuracy 0.9098\n",
      "\n",
      "\n",
      "Epoch 5, train_accuracy 0.9106166666666666\n",
      "Epoch 5, test_accuracy 0.9147\n",
      "\n",
      "\n",
      "Epoch 6, train_accuracy 0.9154333333333333\n",
      "Epoch 6, test_accuracy 0.9196\n",
      "\n",
      "\n",
      "Epoch 7, train_accuracy 0.91915\n",
      "Epoch 7, test_accuracy 0.9235\n",
      "\n",
      "\n",
      "Epoch 8, train_accuracy 0.92265\n",
      "Epoch 8, test_accuracy 0.9255\n",
      "\n",
      "\n",
      "Epoch 9, train_accuracy 0.9259\n",
      "Epoch 9, test_accuracy 0.9281\n",
      "\n",
      "\n",
      "Epoch 10, train_accuracy 0.9291\n",
      "Epoch 10, test_accuracy 0.9298\n",
      "\n",
      "\n",
      "Epoch 11, train_accuracy 0.9318666666666666\n",
      "Epoch 11, test_accuracy 0.9322\n",
      "\n",
      "\n",
      "Epoch 12, train_accuracy 0.9346666666666666\n",
      "Epoch 12, test_accuracy 0.9341\n",
      "\n",
      "\n",
      "Epoch 13, train_accuracy 0.9371833333333334\n",
      "Epoch 13, test_accuracy 0.9362\n",
      "\n",
      "\n",
      "Epoch 14, train_accuracy 0.9393166666666667\n",
      "Epoch 14, test_accuracy 0.9382\n",
      "\n",
      "\n",
      "Epoch 15, train_accuracy 0.9414\n",
      "Epoch 15, test_accuracy 0.9399\n",
      "\n",
      "\n",
      "Epoch 16, train_accuracy 0.9435166666666667\n",
      "Epoch 16, test_accuracy 0.942\n",
      "\n",
      "\n",
      "Epoch 17, train_accuracy 0.9452166666666667\n",
      "Epoch 17, test_accuracy 0.9428\n",
      "\n",
      "\n",
      "Epoch 18, train_accuracy 0.9470833333333334\n",
      "Epoch 18, test_accuracy 0.944\n",
      "\n",
      "\n",
      "Epoch 19, train_accuracy 0.9487\n",
      "Epoch 19, test_accuracy 0.946\n",
      "\n",
      "Finish\n",
      "time: 57.370357036590576 seconds\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, 20):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print('\\nEpoch {}, train_accuracy {}'.format(epoch, get_accuracy(train_loader, model)))\n",
    "    print('Epoch {}, test_accuracy {}\\n'.format(epoch, get_accuracy(test_loader, model)))\n",
    "\n",
    "print('Finish')\n",
    "print('time: {} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ae3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
